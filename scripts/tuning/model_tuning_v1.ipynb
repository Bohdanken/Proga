{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "import scipy\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import scripts.training.Dataset_split as spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "PROJECT_FOLDER = \"../..\"\n",
    "INPUT_DATA_FOLDER = \"data/final_data\"\n",
    "MODEL_FOLDER = \"model\"\n",
    "FINAL_TRAIN_MATRIX = \"final_train_matrix_v1.pkl\"\n",
    "FINAL_DATETIMES = \"final_datetimes_v1\"\n",
    "FINAL_Y = \"final_y_v1\"\n",
    "TUNING_FOLDER = f\"{MODEL_FOLDER}/tuning\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<191715x9026 sparse matrix of type '<class 'numpy.float64'>'\n\twith 129877897 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pickle.load(open(f\"{PROJECT_FOLDER}/{INPUT_DATA_FOLDER}/{FINAL_TRAIN_MATRIX}\", \"rb\"))\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "0         0\n167500    0\n159608    0\n151693    0\n143371    0\n         ..\n135512    0\n119083    0\n51952     0\n16353     0\n191714    0\nName: is_alarm, Length: 191715, dtype: int64"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pickle.load(open(f\"{PROJECT_FOLDER}/{INPUT_DATA_FOLDER}/{FINAL_Y}.pkl\", \"rb\"))\n",
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_dt = pickle.load(open(f\"{PROJECT_FOLDER}/{INPUT_DATA_FOLDER}/{FINAL_DATETIMES}.pkl\", \"rb\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  datetime\n",
      "0      2022-02-26 00:00:00\n",
      "167500 2022-02-26 00:00:00\n",
      "159608 2022-02-26 00:00:00\n",
      "151693 2022-02-26 00:00:00\n",
      "143371 2022-02-26 00:00:00\n",
      "135513 2022-02-26 00:00:00\n",
      "7906   2022-02-26 00:00:00\n",
      "126982 2022-02-26 00:00:00\n",
      "119084 2022-02-26 00:00:00\n",
      "110697 2022-02-26 00:00:00\n",
      "102871 2022-02-26 00:00:00\n",
      "95071  2022-02-26 00:00:00\n",
      "86863  2022-02-26 00:00:00\n",
      "78090  2022-02-26 00:00:00\n",
      "68415  2022-02-26 00:00:00\n",
      "16354  2022-02-26 00:00:00\n",
      "60189  2022-02-26 00:00:00\n",
      "51953  2022-02-26 00:00:00\n",
      "44112  2022-02-26 00:00:00\n",
      "36193  2022-02-26 00:00:00\n",
      "175685 2022-02-26 00:00:00\n",
      "183770 2022-02-26 00:00:00\n",
      "25430  2022-02-26 00:00:00\n",
      "25431  2022-02-26 01:00:00\n",
      "167501 2022-02-26 01:00:00\n",
      "95072  2022-02-26 01:00:00\n",
      "143372 2022-02-26 01:00:00\n",
      "51954  2022-02-26 01:00:00\n",
      "86864  2022-02-26 01:00:00\n",
      "119085 2022-02-26 01:00:00\n"
     ]
    }
   ],
   "source": [
    "print(df_dt.head(30))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "Int64Index([     0, 167500, 159608, 151693, 143371, 135513,   7906, 126982,\n            119084, 110697, 102871,  95071,  86863,  78090,  68415,  16354,\n             60189,  51953,  44112,  36193, 175685, 183770,  25430],\n           dtype='int64')"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dt.loc[df_dt['datetime']==pd.to_datetime(\"2022-02-26 00:00:00\")].index\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import uniform\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import scripts.training.Dataset_split as spl\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression_v7\n"
     ]
    }
   ],
   "source": [
    "TUNING_PATH = f\"{PROJECT_FOLDER}/{TUNING_FOLDER}\"\n",
    "MODEL_NAME = \"logistic_regression_v7\"\n",
    "print(MODEL_NAME)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "def train_model (n_splits, max_iter, solver, min_split, max_split):\n",
    "    split = 1\n",
    "    tss = TimeSeriesSplit(n_splits=n_splits)\n",
    "    MIN_ITERATION = min_split\n",
    "    MAX_ITERATION = max_split\n",
    "    RANDOM_STATE = 1\n",
    "    #getting indexes for df_all_features from splitting df_datetime\n",
    "\n",
    "    for train_index, test_index in zip(*spl.split_dataset(df_dt, tss)):\n",
    "        if(split<MIN_ITERATION):\n",
    "            split+=1\n",
    "            continue\n",
    "        if(split>MAX_ITERATION):\n",
    "            break\n",
    "\n",
    "        model=LogisticRegression(max_iter=max_iter, random_state=RANDOM_STATE, solver=solver, verbose=1, multi_class='ovr', n_jobs=-1)\n",
    "\n",
    "        X_train=X[train_index]\n",
    "        X_test=X[test_index]\n",
    "        y_train=y[train_index]\n",
    "        y_test=y[test_index]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        score = model.score(X_test, y_test)\n",
    "\n",
    "        print(f\"{MODEL_NAME}_split{split}: {score}\")\n",
    "        FOLDER=f\"{TUNING_PATH}/{MODEL_NAME}\"\n",
    "        if not os.path.exists(FOLDER):\n",
    "            os.makedirs(FOLDER)\n",
    "        with open(f\"{TUNING_PATH}/{MODEL_NAME}/{MODEL_NAME}_{solver}_split{split}.pkl\", 'wb') as handle: pickle.dump(model, handle)\n",
    "        split+=1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 623 seconds\n",
      "logistic_regression_v7_split4: 0.8593155893536122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IvarY\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed: 10.4min finished\n"
     ]
    }
   ],
   "source": [
    "train_model(n_splits=4, max_iter=500, min_split=4, max_split=4, solver='saga')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MODEL_NAME' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[36], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43mMODEL_NAME\u001B[49m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_iter\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msplit\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mscore\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'MODEL_NAME' is not defined"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}